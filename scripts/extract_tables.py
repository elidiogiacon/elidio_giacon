import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parent.parent))

import os
import logging
import zipfile
import pdfplumber
import pandas as pd

from dotenv import load_dotenv
from pathlib import Path
from scripts.etl_utils import substituir_siglas
from scripts.scan_pdf_tables import detectar_paginas_com_tabelas



# === CONFIGURA√á√ïES GERAIS ===
load_dotenv()
BASE_DIR = Path(__file__).resolve().parent.parent
ANEXO_DIR = BASE_DIR / "output" / "anexos"
ZIP_PATH = BASE_DIR / "output" / "zips" / "Teste_{elidio_giacon_neto}.zip"  # Arquivo ZIP de entrada (conforme padr√£o solicitado)

# === PDF fixado conforme especifica√ß√£o do desafio t√©cnico ===
# O desafio solicita a extra√ß√£o apenas do Anexo I.
PDF_FILENAME = "Anexo_I_Rol_2021RN_465.2021_RN627L.2024.pdf"
PDF_PATH = ANEXO_DIR / PDF_FILENAME

# === Caminhos de sa√≠da ===
CSV_PATH = BASE_DIR / "output" / "csv" / "rol_procedimentos.csv"
ZIP_OUT = BASE_DIR / "output" / "zips" / "Teste_ElidioGiaconNeto.zip"  # Arquivo ZIP de sa√≠da
LOG_PATH = BASE_DIR / "output" / "logs" / "etapa2_failures.log"

# Criar diret√≥rios de sa√≠da se necess√°rio
for d in [CSV_PATH.parent, LOG_PATH.parent, ZIP_OUT.parent]:
    d.mkdir(parents=True, exist_ok=True)

# === LOG CONFIG ===
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s - %(levelname)s - %(message)s")

def extrair_zip_anexos(zip_path: Path, destino: Path) -> None:
    """
    Extrai os arquivos de um ZIP para o diret√≥rio de destino.

    Args:
        zip_path (Path): Caminho do arquivo ZIP a ser extra√≠do.
        destino (Path): Diret√≥rio onde os arquivos ser√£o extra√≠dos.
    """
    if not destino.exists():
        destino.mkdir(parents=True)
    with zipfile.ZipFile(zip_path, "r") as zipf:
        zipf.extractall(destino)
    logging.info(f"üìÇ Arquivos extra√≠dos de {zip_path.name} para {destino}")

def extrair_tabelas_do_pdf(pdf_path: Path, paginas_validas: list[int]) -> tuple[list[pd.DataFrame], list[int]]:
    """
    Extrai tabelas de um PDF das p√°ginas especificadas.

    Args:
        pdf_path (Path): Caminho do arquivo PDF.
        paginas_validas (list[int]): Lista de n√∫meros de p√°ginas que cont√™m tabelas.

    Returns:
        tuple: Uma tupla contendo:
            - Uma lista de DataFrames com as tabelas extra√≠das.
            - Uma lista de p√°ginas que falharam na extra√ß√£o.
    """
    tabelas: list[pd.DataFrame] = []
    falhas: list[int] = []
    with pdfplumber.open(pdf_path) as pdf:
        for i in paginas_validas:
            try:
                table = pdf.pages[i - 1].extract_table()
                if table:
                    df = pd.DataFrame(table[1:], columns=table[0])
                    # Deduplica√ß√£o segura de colunas
                    seen: dict[str, int] = {}
                    new_cols: list[str] = []
                    for col in df.columns:
                        if col not in seen:
                            seen[col] = 1
                            new_cols.append(col)
                        else:
                            seen[col] += 1
                            new_cols.append(f"{col}_{seen[col]}")
                    df.columns = [col.replace('\n', ' ').strip() for col in new_cols]
                    df["pagina"] = i
                    tabelas.append(df)
                    logging.debug(f"‚úÖ P√°gina {i} extra√≠da")
            except Exception as e:
                falhas.append(i)
                logging.warning(f"‚ùå Falha na p√°gina {i}: {e}")
    return tabelas, falhas

def exportar_csv_e_zip(tabelas: list[pd.DataFrame]) -> None:
    """
    Concatena as tabelas extra√≠das, aplica substitui√ß√£o de siglas, exporta para CSV e compacta em ZIP.

    Args:
        tabelas (list[pd.DataFrame]): Lista de DataFrames das tabelas extra√≠das.
    """
    if not tabelas:
        logging.warning("‚ö†Ô∏è Nenhuma tabela v√°lida para exportar.")
        return
    df_final = pd.concat(tabelas, ignore_index=True)
    df_final = substituir_siglas(df_final)
    df_final.to_csv(CSV_PATH, index=False)
    with zipfile.ZipFile(ZIP_OUT, "w") as zipf:
        zipf.write(CSV_PATH, arcname=CSV_PATH.name)
    logging.info(f"üì¶ CSV exportado para: {CSV_PATH}")
    logging.info(f"üóúÔ∏è ZIP gerado em: {ZIP_OUT}")

def salvar_log_falhas(falhas: list[int]) -> None:
    """
    Salva as p√°ginas que falharam na extra√ß√£o em um arquivo de log.

    Args:
        falhas (list[int]): Lista de n√∫meros de p√°ginas que apresentaram falhas.
    """
    if falhas:
        with open(LOG_PATH, "w", encoding="utf-8") as f:
            for page in falhas:
                f.write(f"Falha na p√°gina {page}\n")
        logging.warning(f"üìù Falhas salvas em: {LOG_PATH}")

def main() -> None:
    """
    Fun√ß√£o principal que orquestra o processo de extra√ß√£o e exporta√ß√£o.
    """
    extrair_zip_anexos(ZIP_PATH, ANEXO_DIR)
    if not PDF_PATH.exists():
        logging.error(f"‚ùå PDF n√£o encontrado: {PDF_PATH}")
        return
    paginas_validas = detectar_paginas_com_tabelas(PDF_PATH)
    if not paginas_validas:
        logging.warning("‚ùå Nenhuma tabela detectada. Encerrando.")
        return
    logging.info(f"üìñ Detectadas {len(paginas_validas)} p√°ginas com tabelas.")
    tabelas, falhas = extrair_tabelas_do_pdf(PDF_PATH, paginas_validas)
    exportar_csv_e_zip(tabelas)
    salvar_log_falhas(falhas)
    logging.info(f"‚úÖ Tabelas extra√≠das: {len(tabelas)} / Falhas: {len(falhas)}")

if __name__ == "__main__":
    main()
